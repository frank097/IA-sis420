{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1NHPmCAc30pvm5EX8COpk3LKqMDVlBzen",
      "authorship_tag": "ABX9TyNgBzypYd0gUZCKUHYeUKHw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frank097/IA-sis420/blob/main/Pregunta2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Nombre : Franklin Correa Paco\n",
        "#Carrera: Ing. de Sistemas\n",
        "#Ejercicio 2 del examen final\n",
        "#\n",
        "#modelo de redes neuronales para un dataset de diabetes de mas de  253000 datos y 22 columnas"
      ],
      "metadata": {
        "id": "G0hjsabWRzhJ"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "id": "02rs6-EF8YMU"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "# utilizado para la manipulación de directorios y rutas\n",
        "import os\n",
        "\n",
        "# Cálculo científico y vectorial para python\n",
        "import numpy as np\n",
        "\n",
        "# Libreria para graficos\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# Modulo de optimizacion en scipy\n",
        "from scipy import optimize\n",
        "\n",
        "# le dice a matplotlib que incruste gráficos en el cuaderno\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP:\n",
        "    def __init__(self, layers):\n",
        "        # el MLP es una lista de capas\n",
        "        self.layers = layers\n",
        "\n",
        "    def __call__(self, x):\n",
        "        # calculamos la salida del modelo aplicando\n",
        "        # cada capa de manera secuencial\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "kG8FuWk5LrgW"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer():\n",
        "    def __init__(self):\n",
        "        self.params = []\n",
        "        self.grads = []\n",
        "\n",
        "    def __call__(self, x):\n",
        "        # por defecto, devolver los inputs\n",
        "        # cada capa hará algo diferente aquí\n",
        "        return x\n",
        "\n",
        "    def backward(self, grad):\n",
        "        # cada capa, calculará sus gradientes\n",
        "        # y los devolverá para las capas siguientes\n",
        "        return grad\n",
        "\n",
        "    def update(self, params):\n",
        "        # si hay parámetros, los actualizaremos\n",
        "        # con lo que nos de el optimizer\n",
        "        return"
      ],
      "metadata": {
        "id": "1mzDug5fLvrL"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear(Layer):\n",
        "    def __init__(self, d_in, d_out):\n",
        "        # pesos de la capa\n",
        "        self.w = np.random.normal(loc=0.0,\n",
        "                                  scale=np.sqrt(2/(d_in+d_out)),\n",
        "                                  size=(d_in, d_out))\n",
        "        self.b = np.zeros(d_out)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        self.x = x\n",
        "        self.params = [self.w, self.b]\n",
        "        # salida del preceptrón\n",
        "        return np.dot(x, self.w) + self.b\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        # gradientes para la capa siguiente (BACKPROP)\n",
        "        grad = np.dot(grad_output, self.w.T)\n",
        "        self.grad_w = np.dot(self.x.T, grad_output)\n",
        "        # gradientes para actualizar pesos\n",
        "        self.grad_b = grad_output.mean(axis=0)*self.x.shape[0]\n",
        "        self.grads = [self.grad_w, self.grad_b]\n",
        "        return grad\n",
        "\n",
        "    def update(self, params):\n",
        "        self.w, self.b = params"
      ],
      "metadata": {
        "id": "nMYkEsIHL3pO"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#funciones de activacion\n",
        "class ReLU(Layer):\n",
        "    def __call__(self, x):\n",
        "        self.x = x\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        grad = self.x > 0\n",
        "        return grad_output*grad\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def softmax(x):\n",
        "    return np.exp(x) / np.exp(x).sum(axis=-1,keepdims=True)\n",
        "\n",
        "class Sigmoid(Layer):\n",
        "    def __call__(self, x):\n",
        "        self.x = x\n",
        "        return sigmoid(x)\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        grad = sigmoid(self.x)*(1 - sigmoid(self.x))\n",
        "        return grad_output*grad"
      ],
      "metadata": {
        "id": "Pr00qdBkL9-g"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Optimizador, stocastic greadent descent\n",
        "class SGD():\n",
        "    def __init__(self, net, lr):\n",
        "        self.net = net\n",
        "        self.lr = lr\n",
        "\n",
        "    def update(self):\n",
        "        for layer in self.net.layers:\n",
        "            layer.update([\n",
        "                params - self.lr*grads\n",
        "                for params, grads in zip(layer.params, layer.grads)\n",
        "            ])"
      ],
      "metadata": {
        "id": "IbTOucJ0MDOO"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Loss():\n",
        "    def __init__(self, net):\n",
        "        self.net = net\n",
        "\n",
        "    def backward(self):\n",
        "        # derivada de la loss function con respecto\n",
        "        # a la salida del MLP\n",
        "        grad = self.grad_loss()\n",
        "        # BACKPROPAGATION\n",
        "        for layer in reversed(self.net.layers):\n",
        "            grad = layer.backward(grad)\n",
        "\n",
        "class MSE(Loss):#proporciona una implementación del error cuadrático medio (MSE) y su gradiente\n",
        "    def __call__(self, output, target):\n",
        "        self.output, self.target = output, target.reshape(output.shape)\n",
        "        loss = np.mean((self.output - self.target)**2)\n",
        "        return loss.mean()\n",
        "\n",
        "    def grad_loss(self):\n",
        "        return self.output -  self.target\n",
        "\n",
        "class BCE(Loss):# proporciona una implementación de la Binary Cross-Entropy (BCE) y su gradiente, que son útiles en problemas de clasificación binaria\n",
        "    def __call__(self, output, target):\n",
        "        self.output, self.target = output, target.reshape(output.shape)\n",
        "        loss = - np.mean(self.target*np.log(self.output) - (1 - self.target)*np.log(1 - self.output))\n",
        "        return loss.mean()\n",
        "\n",
        "    def grad_loss(self):\n",
        "        return self.output -  self.target\n",
        "\n",
        "class CrossEntropy(Loss): #proporciona una implementación de la función de pérdida\n",
        "    def __call__(self, output, target):\n",
        "        self.output, self.target = output, target\n",
        "        logits = output[np.arange(len(output)), target]\n",
        "        loss = - logits + np.log(np.sum(np.exp(output), axis=-1))\n",
        "        loss = loss.mean()\n",
        "        return loss\n",
        "\n",
        "    def grad_loss(self):\n",
        "        answers = np.zeros_like(self.output)\n",
        "        answers[np.arange(len(self.output)), self.target] = 1\n",
        "        return (- answers + softmax(self.output)) / self.output.shape[0]"
      ],
      "metadata": {
        "id": "lTVxIj2iMIuQ"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#Carga de dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/sis420/examen final/dataset/diabetes_012_health_indicators_BRFSS2015.csv')"
      ],
      "metadata": {
        "id": "x0ufto6kMOsf"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPu9dCZHMWTt",
        "outputId": "01bae0d7-dd50-481c-9f8b-b146cb8fce4c"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 253680 entries, 0 to 253679\n",
            "Data columns (total 22 columns):\n",
            " #   Column                Non-Null Count   Dtype  \n",
            "---  ------                --------------   -----  \n",
            " 0   Diabetes_012          253680 non-null  float64\n",
            " 1   HighBP                253680 non-null  float64\n",
            " 2   HighChol              253680 non-null  float64\n",
            " 3   CholCheck             253680 non-null  float64\n",
            " 4   BMI                   253680 non-null  float64\n",
            " 5   Smoker                253680 non-null  float64\n",
            " 6   Stroke                253680 non-null  float64\n",
            " 7   HeartDiseaseorAttack  253680 non-null  float64\n",
            " 8   PhysActivity          253680 non-null  float64\n",
            " 9   Fruits                253680 non-null  float64\n",
            " 10  Veggies               253680 non-null  float64\n",
            " 11  HvyAlcoholConsump     253680 non-null  float64\n",
            " 12  AnyHealthcare         253680 non-null  float64\n",
            " 13  NoDocbcCost           253680 non-null  float64\n",
            " 14  GenHlth               253680 non-null  float64\n",
            " 15  MentHlth              253680 non-null  float64\n",
            " 16  PhysHlth              253680 non-null  float64\n",
            " 17  DiffWalk              253680 non-null  float64\n",
            " 18  Sex                   253680 non-null  float64\n",
            " 19  Age                   253680 non-null  float64\n",
            " 20  Education             253680 non-null  float64\n",
            " 21  Income                253680 non-null  float64\n",
            "dtypes: float64(22)\n",
            "memory usage: 42.6 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPSjisxyMwYj",
        "outputId": "3ba9d120-5b26-4749-f80a-f84f2859de3d"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 253680 entries, 0 to 253679\n",
            "Data columns (total 22 columns):\n",
            " #   Column                Non-Null Count   Dtype  \n",
            "---  ------                --------------   -----  \n",
            " 0   Diabetes_012          253680 non-null  float64\n",
            " 1   HighBP                253680 non-null  float64\n",
            " 2   HighChol              253680 non-null  float64\n",
            " 3   CholCheck             253680 non-null  float64\n",
            " 4   BMI                   253680 non-null  float64\n",
            " 5   Smoker                253680 non-null  float64\n",
            " 6   Stroke                253680 non-null  float64\n",
            " 7   HeartDiseaseorAttack  253680 non-null  float64\n",
            " 8   PhysActivity          253680 non-null  float64\n",
            " 9   Fruits                253680 non-null  float64\n",
            " 10  Veggies               253680 non-null  float64\n",
            " 11  HvyAlcoholConsump     253680 non-null  float64\n",
            " 12  AnyHealthcare         253680 non-null  float64\n",
            " 13  NoDocbcCost           253680 non-null  float64\n",
            " 14  GenHlth               253680 non-null  float64\n",
            " 15  MentHlth              253680 non-null  float64\n",
            " 16  PhysHlth              253680 non-null  float64\n",
            " 17  DiffWalk              253680 non-null  float64\n",
            " 18  Sex                   253680 non-null  float64\n",
            " 19  Age                   253680 non-null  float64\n",
            " 20  Education             253680 non-null  float64\n",
            " 21  Income                253680 non-null  float64\n",
            "dtypes: float64(22)\n",
            "memory usage: 42.6 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = data.iloc[:, :21]\n",
        "y = data.iloc[:, 21]\n",
        "m = y.size\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "print(x)\n",
        "print('---'*20)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNz7dyMKNDDE",
        "outputId": "781398a4-00bd-4bcc-d8f6-49c11f82147c"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(253680, 21)\n",
            "(253680,)\n",
            "        Diabetes_012  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
            "0                0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
            "1                0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
            "2                0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
            "3                0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
            "4                0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
            "...              ...     ...       ...        ...   ...     ...     ...   \n",
            "253675           0.0     1.0       1.0        1.0  45.0     0.0     0.0   \n",
            "253676           2.0     1.0       1.0        1.0  18.0     0.0     0.0   \n",
            "253677           0.0     0.0       0.0        1.0  28.0     0.0     0.0   \n",
            "253678           0.0     1.0       0.0        1.0  23.0     0.0     0.0   \n",
            "253679           2.0     1.0       1.0        1.0  25.0     0.0     0.0   \n",
            "\n",
            "        HeartDiseaseorAttack  PhysActivity  Fruits  ...  HvyAlcoholConsump  \\\n",
            "0                        0.0           0.0     0.0  ...                0.0   \n",
            "1                        0.0           1.0     0.0  ...                0.0   \n",
            "2                        0.0           0.0     1.0  ...                0.0   \n",
            "3                        0.0           1.0     1.0  ...                0.0   \n",
            "4                        0.0           1.0     1.0  ...                0.0   \n",
            "...                      ...           ...     ...  ...                ...   \n",
            "253675                   0.0           0.0     1.0  ...                0.0   \n",
            "253676                   0.0           0.0     0.0  ...                0.0   \n",
            "253677                   0.0           1.0     1.0  ...                0.0   \n",
            "253678                   0.0           0.0     1.0  ...                0.0   \n",
            "253679                   1.0           1.0     1.0  ...                0.0   \n",
            "\n",
            "        AnyHealthcare  NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  \\\n",
            "0                 1.0          0.0      5.0      18.0      15.0       1.0   \n",
            "1                 0.0          1.0      3.0       0.0       0.0       0.0   \n",
            "2                 1.0          1.0      5.0      30.0      30.0       1.0   \n",
            "3                 1.0          0.0      2.0       0.0       0.0       0.0   \n",
            "4                 1.0          0.0      2.0       3.0       0.0       0.0   \n",
            "...               ...          ...      ...       ...       ...       ...   \n",
            "253675            1.0          0.0      3.0       0.0       5.0       0.0   \n",
            "253676            1.0          0.0      4.0       0.0       0.0       1.0   \n",
            "253677            1.0          0.0      1.0       0.0       0.0       0.0   \n",
            "253678            1.0          0.0      3.0       0.0       0.0       0.0   \n",
            "253679            1.0          0.0      2.0       0.0       0.0       0.0   \n",
            "\n",
            "        Sex   Age  Education  \n",
            "0       0.0   9.0        4.0  \n",
            "1       0.0   7.0        6.0  \n",
            "2       0.0   9.0        4.0  \n",
            "3       0.0  11.0        3.0  \n",
            "4       0.0  11.0        5.0  \n",
            "...     ...   ...        ...  \n",
            "253675  1.0   5.0        6.0  \n",
            "253676  0.0  11.0        2.0  \n",
            "253677  0.0   2.0        5.0  \n",
            "253678  1.0   7.0        5.0  \n",
            "253679  0.0   9.0        6.0  \n",
            "\n",
            "[253680 rows x 21 columns]\n",
            "------------------------------------------------------------\n",
            "0         3.0\n",
            "1         1.0\n",
            "2         8.0\n",
            "3         6.0\n",
            "4         4.0\n",
            "         ... \n",
            "253675    7.0\n",
            "253676    4.0\n",
            "253677    2.0\n",
            "253678    1.0\n",
            "253679    2.0\n",
            "Name: Income, Length: 253680, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crea un nuevo DataFrame con los datos modificados\n",
        "nuevo_data = data.copy()\n",
        "# Guardar el dataset actualizado en un nuevo archivo\n",
        "nuevo_data.to_csv('diabetes1.csv', index=False)"
      ],
      "metadata": {
        "id": "GVQrCBxpNSBy"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.loadtxt(\"/content/diabetes1.csv\", delimiter=',',skiprows=1)\n",
        "# print(data)\n",
        "x, y = data[:, :21].astype(int), data[:, 0].astype(int)\n",
        "x = x.reshape(len(x),21)\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kp8XjCTkNdx5",
        "outputId": "e579a701-6e1e-4434-d53a-b02081885f61"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(253680, 21)\n",
            "(253680,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = x[:800] , x[800:] , y[:800].astype(np.float64), y[800:].astype(np.float64)\n",
        "x_train.shape , x_test.shape\n",
        "\n",
        "y_train.shape , y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftZm7YZKNvCs",
        "outputId": "fa5c440a-ec00-476b-e7de-b8c11a2b7b42"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((800,), (252880,))"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "  return np.maximum(0, x)\n",
        "\n",
        "def reluPrime(x):\n",
        "  return x > 0"
      ],
      "metadata": {
        "id": "boWMe0uFN0Iu"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear(x):\n",
        "    return x\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def softmax(x):\n",
        "    return np.exp(x) / np.exp(x).sum(axis=-1,keepdims=True)"
      ],
      "metadata": {
        "id": "1yYIEipHN4aQ"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean Square Error -> usada para regresión (con activación lineal)\n",
        "def mse(y, y_hat):\n",
        "    return np.mean((y_hat - y.reshape(y_hat.shape))**2)\n",
        "\n",
        "# Binary Cross Entropy -> usada para clasificación binaria (con sigmoid)\n",
        "def bce(y, y_hat):\n",
        "    return - np.mean(y.reshape(y_hat.shape)*np.log(y_hat) - (1 - y.reshape(y_hat.shape))*np.log(1 - y_hat))\n",
        "\n",
        "# Cross Entropy (aplica softmax + cross entropy de manera estable) -> usada para clasificación multiclase\n",
        "def crossentropy(y, y_hat):\n",
        "    logits = y_hat[np.arange(len(y_hat)),y]\n",
        "    entropy = - logits + np.log(np.sum(np.exp(y_hat),axis=-1))\n",
        "    return entropy.mean()"
      ],
      "metadata": {
        "id": "J2mP2WN9N8CO"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_mse(y, y_hat):\n",
        "    return y_hat - y.reshape(y_hat.shape)\n",
        "\n",
        "def grad_bce(y, y_hat):\n",
        "    return y_hat - y.reshape(y_hat.shape)\n",
        "\n",
        "def grad_crossentropy(y, y_hat):\n",
        "    answers = np.zeros_like(y_hat)\n",
        "    answers[np.arange(len(y_hat)),y] = 1\n",
        "    return (- answers + softmax(y_hat)) / y_hat.shape[0]"
      ],
      "metadata": {
        "id": "sk8O05AQOHiX"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clase base MLP\n",
        "\n",
        "class MLP():\n",
        "  def __init__(self, D_in, H, D_out, loss, grad_loss, activation):\n",
        "    # pesos de la capa 1\n",
        "    self.w1, self.b1 = np.random.normal(loc=0.0,\n",
        "                                  scale=np.sqrt(2/(D_in+H)),\n",
        "                                  size=(D_in, H)), np.zeros(H)\n",
        "    # pesos de la capa 2\n",
        "    self.w2, self.b2 = np.random.normal(loc=0.0,\n",
        "                                  scale=np.sqrt(2/(H+D_out)),\n",
        "                                  size=(H, D_out)), np.zeros(D_out)\n",
        "    self.ws = []\n",
        "    # función de pérdida y derivada\n",
        "    self.loss = loss\n",
        "    self.grad_loss = grad_loss\n",
        "    # función de activación\n",
        "    self.activation = activation\n",
        "\n",
        "  def __call__(self, x):\n",
        "    # salida de la capa 1\n",
        "    self.h_pre = np.dot(x, self.w1) + self.b1\n",
        "    self.h = relu(self.h_pre)\n",
        "    # salida del MLP\n",
        "    y_hat = np.dot(self.h, self.w2) + self.b2\n",
        "    return self.activation(y_hat)\n",
        "\n",
        "  def fit(self, X, Y, epochs = 100, lr = 0.001, batch_size=None, verbose=True, log_each=1):\n",
        "    batch_size = len(X) if batch_size == None else batch_size\n",
        "    batches = len(X) // batch_size\n",
        "    l = []\n",
        "    for e in range(1,epochs+1):\n",
        "        # Mini-Batch Gradient Descent\n",
        "        _l = []\n",
        "        for b in range(batches):\n",
        "            # batch de datos\n",
        "            x = X[b*batch_size:(b+1)*batch_size]\n",
        "            y = Y[b*batch_size:(b+1)*batch_size]\n",
        "            # salida del perceptrón\n",
        "            y_pred = self(x)\n",
        "            # función de pérdida\n",
        "            loss = self.loss(y, y_pred)\n",
        "            _l.append(loss)\n",
        "            # Backprop\n",
        "            dldy = self.grad_loss(y, y_pred)\n",
        "            grad_w2 = np.dot(self.h.T, dldy)\n",
        "            grad_b2 = dldy.mean(axis=0)\n",
        "            dldh = np.dot(dldy, self.w2.T)*reluPrime(self.h_pre)\n",
        "            grad_w1 = np.dot(x.T, dldh)\n",
        "            grad_b1 = dldh.mean(axis=0)\n",
        "            # Update (GD)\n",
        "            self.w1 = self.w1 - lr * grad_w1\n",
        "            self.b1 = self.b1 - lr * grad_b1\n",
        "            self.w2 = self.w2 - lr * grad_w2\n",
        "            self.b2 = self.b2 - lr * grad_b2\n",
        "        l.append(np.mean(_l))\n",
        "        # guardamos pesos intermedios para visualización\n",
        "        self.ws.append((\n",
        "            self.w1.copy(),\n",
        "            self.b1.copy(),\n",
        "            self.w2.copy(),\n",
        "            self.b2.copy()\n",
        "        ))\n",
        "        if verbose and not e % log_each:\n",
        "            print(f'Epoch: {e}/{epochs}, Loss: {np.mean(l):.5f}')\n",
        "\n",
        "  def predict(self, ws, x):\n",
        "    w1, b1, w2, b2 = ws\n",
        "    h = relu(np.dot(x, w1) + b1)\n",
        "    y_hat = np.dot(h, w2) + b2\n",
        "    return self.activation(y_hat)\n",
        "  def evaluate(perceptron, x, t = 0.5):\n",
        "    w = perceptron.ws[-1]\n",
        "    x = np.c_[np.ones(len(x)), x]\n",
        "    y = perceptron(w, x)\n",
        "    return (y > t).astype(np.float64)"
      ],
      "metadata": {
        "id": "Zmai1tIIOLpE"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP para regresión\n",
        "class MLPRegression(MLP):\n",
        "    def __init__(self, D_in, H, D_out):\n",
        "        super().__init__(D_in, H, D_out, mse, grad_mse, linear)\n",
        "\n",
        "# MLP para clasificación binaria\n",
        "class MLPBinaryClassification(MLP):\n",
        "    def __init__(self, D_in, H, D_out):\n",
        "        super().__init__(D_in, H, D_out, bce, grad_bce, sigmoid)\n",
        "\n",
        "# MLP para clasificación multiclase\n",
        "class MLPClassification(MLP):\n",
        "    def __init__(self, D_in, H, D_out):\n",
        "        super().__init__(D_in, H, D_out, crossentropy, grad_crossentropy, linear)"
      ],
      "metadata": {
        "id": "EhdffF2VOR_s"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLPBinaryClassification(D_in=21, H=2, D_out=1)\n",
        "epochs, lr = 120, 0.04\n",
        "\n",
        "# normalización datos\n",
        "x_mean = np.mean(x_train)\n",
        "x_std = np.std(x_train)\n",
        "x_std = np.nan_to_num(x_std, nan=1.0)\n",
        "\n",
        "\n",
        "# Calcula x_norm\n",
        "x_norm = (x_train - x_mean) / x_std\n",
        "\n",
        "model.fit(x, y, epochs=100, batch_size=50, log_each=10)\n",
        "#model.fit(x_norm, y_train, epochs, lr, batch_size=1, log_each=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhxKl0yIOW9r",
        "outputId": "20c8a3ad-075b-400e-c59a-fecf3d32e031"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10/100, Loss: 0.07983\n",
            "Epoch: 20/100, Loss: 0.09635\n",
            "Epoch: 30/100, Loss: 0.10186\n",
            "Epoch: 40/100, Loss: 0.10461\n",
            "Epoch: 50/100, Loss: 0.10626\n",
            "Epoch: 60/100, Loss: 0.10737\n",
            "Epoch: 70/100, Loss: 0.10815\n",
            "Epoch: 80/100, Loss: 0.10874\n",
            "Epoch: 90/100, Loss: 0.10920\n",
            "Epoch: 100/100, Loss: 0.10957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# últimos pesos encontrados\n",
        "\n",
        "w = model.ws[-1]\n",
        "w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAwpliVGOflm",
        "outputId": "7230fa32-4a33-463e-debd-3da73296cf97"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.72720198,  0.6711891 ],\n",
              "        [ 0.04174955, -0.11481103],\n",
              "        [ 0.09036221, -0.20200782],\n",
              "        [ 0.03729196, -0.4091694 ],\n",
              "        [-0.48816982, -0.58592956],\n",
              "        [ 0.07088762,  0.43413077],\n",
              "        [-0.70082454,  0.39666759],\n",
              "        [-0.46727289,  0.36947011],\n",
              "        [-0.21822293, -0.43684629],\n",
              "        [ 0.01219007,  0.04897933],\n",
              "        [ 0.38222955, -0.13000514],\n",
              "        [-0.00746263, -0.07996517],\n",
              "        [ 0.01848628, -0.06525765],\n",
              "        [-0.11091984, -0.11018406],\n",
              "        [ 0.14255934,  0.29517914],\n",
              "        [-0.01036856, -0.3088485 ],\n",
              "        [ 0.17412241,  0.15467023],\n",
              "        [ 0.17696758,  0.22385186],\n",
              "        [ 0.11613038, -0.19559391],\n",
              "        [-0.02582559, -0.461167  ],\n",
              "        [-0.05155037, -0.2929751 ]]),\n",
              " array([ 0.       , -0.0005934]),\n",
              " array([[0.27121853],\n",
              "        [1.18997767]]),\n",
              " array([-0.85803269]))"
            ]
          },
          "metadata": {},
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Primeros 5 datos de entrada de prueba (X_test):\")\n",
        "print(x_test[:5])\n",
        "\n",
        "print(\"Primeras 5 etiquetas de prueba (y_test):\")\n",
        "print(y_test[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi70-48MOllM",
        "outputId": "a6058aba-6d3e-4f3f-ed5c-012ce6f435e8"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primeros 5 datos de entrada de prueba (X_test):\n",
            "[[ 0  0  0  1 27  0  0  0  1  0  0  0  1  0  3  0  0  0  0  1  4]\n",
            " [ 2  1  1  1 34  1  0  0  1  0  1  0  1  0  4  0  0  0  1  9  5]\n",
            " [ 0  0  0  1 32  0  0  0  1  1  1  0  1  0  4  0  0  0  0  8  5]\n",
            " [ 0  1  1  1 26  0  0  0  1  0  0  0  0  1  4  0  0  0  0  8  4]\n",
            " [ 0  0  0  1 29  0  0  0  0  0  0  0  1  0  1  0  0  0  1  4  4]]\n",
            "Primeras 5 etiquetas de prueba (y_test):\n",
            "[0. 2. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nuevo punto\n",
        "x_new = x_test\n",
        "X_new = [0, 0, 0, 1, 29, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 4, 4]\n",
        "y_pred = model.predict(w, X_new)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWlvT6xxOuvt",
        "outputId": "88323ca4-55c4-4450-8a82-7d71f785ea4c"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.29775054])"
            ]
          },
          "metadata": {},
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_pred, y):\n",
        "    return np.sum(y_pred == y) / len(y)"
      ],
      "metadata": {
        "id": "lILhb-UfPKnA"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x, y, epochs=150, batch_size=50, log_each=10)\n",
        "\n",
        "#model.fit(X, Y, epochs=50, batch_size=250, verbose=2, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5t-Hl5fHFqKq",
        "outputId": "92126bea-4fba-4385-fcaa-865aa9347226"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10/150, Loss: 0.11287\n",
            "Epoch: 20/150, Loss: 0.11287\n",
            "Epoch: 30/150, Loss: 0.11287\n",
            "Epoch: 40/150, Loss: 0.11287\n",
            "Epoch: 50/150, Loss: 0.11287\n",
            "Epoch: 60/150, Loss: 0.11287\n",
            "Epoch: 70/150, Loss: 0.11287\n",
            "Epoch: 80/150, Loss: 0.11287\n",
            "Epoch: 90/150, Loss: 0.11287\n",
            "Epoch: 100/150, Loss: 0.11287\n",
            "Epoch: 110/150, Loss: 0.11287\n",
            "Epoch: 120/150, Loss: 0.11287\n",
            "Epoch: 130/150, Loss: 0.11287\n",
            "Epoch: 140/150, Loss: 0.11287\n",
            "Epoch: 150/150, Loss: 0.11287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(x,y)\n",
        "print(\"%s: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "Dag5Ko26Vj7x",
        "outputId": "ada91e2c-c610-4d5d-8614-fc56a7f7be60"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-224-258675483235>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-216-3cf343e6e480>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(perceptron, x, t)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperceptron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: MLP.__call__() takes 2 positional arguments but 3 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E6ADilO2a7xU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}